'use client';

import { useState, useRef, useEffect, useCallback } from 'react';
import styles from './CameraView.module.css';
import LoadingSpinner from '../LoadingSpinner/LoadingSpinner';
import ResultPopup from '../ResultPopup/ResultPopup';
import { HistoryItem, ApiResult } from '@/types';

// face-api.js import
import * as faceapi from 'face-api.js';

interface CameraViewProps {
  onNewHistoryItem: (item: HistoryItem) => void;
}

const CameraView: React.FC<CameraViewProps> = ({ onNewHistoryItem }) => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [isCameraReady, setIsCameraReady] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [isModelsLoading, setIsModelsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [showPopup, setShowPopup] = useState(false);
  const [capturedImageForPopup, setCapturedImageForPopup] = useState<string | null>(null);
  const [apiResultForPopup, setApiResultForPopup] = useState<ApiResult | null>(null);

  // ëª¨ë¸ ë¡œë“œ ë° ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì„¤ì •
  useEffect(() => {
    const loadModels = async () => {
      try {
        await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
        await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
        await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        await faceapi.nets.faceExpressionNet.loadFromUri('/models');
        console.log("Face-api.js ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!");
        setIsModelsLoading(false);
      } catch (err) {
        console.error("Face-api.js ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:", err);
        setError("AI ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆì–´ìš”. ğŸ˜¢");
        setIsModelsLoading(false);
      }
    };

    const setupCamera = async () => {
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        setError("ì¹´ë©”ë¼ ì§€ì› ì•ˆí•¨.");
        setIsCameraReady(false);
        return;
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadedmetadata = () => {
            videoRef.current?.play().catch(playError => {
              console.error("ì¹´ë©”ë¼ ì¬ìƒ ì‹¤íŒ¨:", playError);
              setError("ì¹´ë©”ë¼ë¥¼ ì¬ìƒí•  ìˆ˜ ì—†ì–´ìš”. ë‹¤ë¥¸ ì•±ì—ì„œ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
            });
            setIsCameraReady(true);
          };
        }
      } catch (err) {
        console.error("ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨: ", err);
        setError("ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•´ìš”.");
        setIsCameraReady(false);
      }
    };

    loadModels().then(() => {
      setupCamera();
    });

    return () => {
      if (videoRef.current && videoRef.current.srcObject) {
        const stream = videoRef.current.srcObject as MediaStream;
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  // ì‹¤ì‹œê°„ ì–¼êµ´ ê°ì§€ ë° ê°ì • ë¶„ì„
  useEffect(() => {
    if (!isCameraReady || isModelsLoading || !videoRef.current || !canvasRef.current) {
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');

    if (!context) {
      console.error("ìº”ë²„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ìš”.");
      return;
    }

    let animationFrameId: number;

    const detectFaces = async () => {
      if (video.paused || video.ended || !video.videoWidth || !video.videoHeight) {
        return;
      }

      // ìº”ë²„ìŠ¤ í¬ê¸°ë¥¼ ë¹„ë””ì˜¤ì˜ ì‹¤ì œ í¬ê¸°ë¡œ ì„¤ì •
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      
      // ìº”ë²„ìŠ¤ í¬ê¸° ì—…ë°ì´íŠ¸
      canvas.width = displaySize.width;
      canvas.height = displaySize.height;
      
      faceapi.matchDimensions(canvas, displaySize);

      try {
        // ì–¼êµ´ ê°ì§€ ë° ê°ì • ë¶„ì„
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 416, scoreThreshold: 0.5 }))
          .withFaceLandmarks()
          .withFaceExpressions();

        // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
        context.clearRect(0, 0, canvas.width, canvas.height);

        if (detections.length > 0) {
          // ê°ì§€ëœ ê²°ê³¼ë¥¼ ìº”ë²„ìŠ¤ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
          const resizedDetections = faceapi.resizeResults(detections, displaySize);

          // ì–¼êµ´ ì™¸ê³½ì„  ê·¸ë¦¬ê¸° (ë°”ìš´ë”© ë°•ìŠ¤)
          faceapi.draw.drawDetections(canvas, resizedDetections);

          // ëœë“œë§ˆí¬ ì ë“¤ ê·¸ë¦¬ê¸° (ì„ íƒì‚¬í•­)
          faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

          // ê° ì–¼êµ´ì— ëŒ€í•´ ê°ì • í‘œì‹œ
          resizedDetections.forEach((detection) => {
            const { x, y } = detection.detection.box;
            const expressions = detection.expressions;
            
            // ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ê°ì • ì°¾ê¸°
            const maxExpression = Object.keys(expressions).reduce((a, b) => 
              expressions[a as keyof typeof expressions] > expressions[b as keyof typeof expressions] ? a : b
            );
            const maxValue = expressions[maxExpression as keyof typeof expressions] as number;

            // í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ì„¤ì •
            context.fillStyle = '#00ff00';
            context.font = '16px Arial';
            context.strokeStyle = '#000000';
            context.lineWidth = 2;

            // ì£¼ìš” ê°ì • í‘œì‹œ
            const mainText = `${maxExpression}: ${(maxValue * 100).toFixed(1)}%`;
            context.strokeText(mainText, x, y - 10);
            context.fillText(mainText, x, y - 10);

            // ëª¨ë“  ê°ì • í™•ë¥  í‘œì‹œ (ìƒìœ„ 3ê°œ)
            const sortedExpressions = Object.entries(expressions)
              .sort(([,a], [,b]) => b - a)
              .slice(0, 3);

            sortedExpressions.forEach(([emotion, probability], index) => {
              const text = `${emotion}: ${(probability * 100).toFixed(1)}%`;
              const yPos = y + detection.detection.box.height + 20 + (index * 20);
              
              context.strokeText(text, x, yPos);
              context.fillText(text, x, yPos);
            });
          });
        }
      } catch (error) {
        console.error('ì–¼êµ´ ê°ì§€ ì¤‘ ì˜¤ë¥˜:', error);
      }

      // ë‹¤ìŒ í”„ë ˆì„ ìš”ì²­
      animationFrameId = requestAnimationFrame(detectFaces);
    };

    // ë¹„ë””ì˜¤ê°€ ì¬ìƒ ì¤‘ì´ë©´ ê°ì§€ ì‹œì‘
    const startDetection = () => {
      if (video.readyState >= 2) { // HAVE_CURRENT_DATA
        detectFaces();
      }
    };

    // ë¹„ë””ì˜¤ ì¤€ë¹„ ìƒíƒœ í™•ì¸
    if (video.readyState >= 2) {
      startDetection();
    } else {
      video.addEventListener('loadeddata', startDetection);
    }

    // ì •ë¦¬ í•¨ìˆ˜
    return () => {
      if (animationFrameId) {
        cancelAnimationFrame(animationFrameId);
      }
      video.removeEventListener('loadeddata', startDetection);
    };
  }, [isCameraReady, isModelsLoading]);

  const handleTakePhoto = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current || !isCameraReady || isModelsLoading) {
      setError("ì¹´ë©”ë¼ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ê±°ë‚˜, AI ëª¨ë¸ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤.");
      return;
    }

    setIsLoading(true);
    setError(null);

    const video = videoRef.current;
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = video.videoWidth;
    tempCanvas.height = video.videoHeight;

    const context = tempCanvas.getContext('2d');
    if (!context) {
      setError("ìº”ë²„ìŠ¤ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ìš”.");
      setIsLoading(false);
      return;
    }

    // ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì„ì‹œ ìº”ë²„ìŠ¤ì— ê·¸ë¦½ë‹ˆë‹¤.
    context.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

    const imageDataUrl = tempCanvas.toDataURL('image/jpeg');
    setCapturedImageForPopup(imageDataUrl);

    const imageBlob = await new Promise<Blob | null>(resolve => tempCanvas.toBlob(resolve, 'image/jpeg'));

    if (!imageBlob) {
      setError("ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Blobìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”.");
      setIsLoading(false);
      return;
    }

    const formData = new FormData();
    formData.append('photo', imageBlob, 'capture.jpg');

    try {
      console.log("ì„œë²„ë¡œ ì „ì†¡ë  ì´ë¯¸ì§€ ë°ì´í„° (Blob):", imageBlob);
      console.log("ì„œë²„ë¡œ ì „ì†¡ë  FormData:", formData.get('photo'));
      await new Promise(resolve => setTimeout(resolve, 2000));
      const mockResult: ApiResult = {
        celebrityName: "ì•„ì´ìœ ",
      };

      setApiResultForPopup(mockResult);
      setShowPopup(true);

      const newHistoryEntry: HistoryItem = {
        id: new Date().toISOString(),
        submittedImageUrl: imageDataUrl,
        celebrityName: mockResult.celebrityName,
      };
      onNewHistoryItem(newHistoryEntry);

    } catch (apiError: any) {
      console.error("API í†µì‹  ì¤‘ ì—ëŸ¬ ë°œìƒ:", apiError);
      setError(apiError.message || "ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ğŸ˜­");
      setCapturedImageForPopup(null);
      setApiResultForPopup(null);
    } finally {
      setIsLoading(false);
    }
  }, [isCameraReady, isModelsLoading, onNewHistoryItem]);

  const handleClosePopup = () => {
    setShowPopup(false);
    setCapturedImageForPopup(null);
    setApiResultForPopup(null);
  };

  if (error && !isLoading) {
    return <div className={styles.errorMessage}>{error}</div>;
  }

  if (isModelsLoading) {
    return (
      <div className={styles.cameraContainer}>
        <LoadingSpinner/>
      </div>
    );
  }

  return (
    <div className={styles.cameraContainer}>
      {isLoading && <LoadingSpinner />}

      <video
        ref={videoRef}
        className={styles.videoFeed}
        playsInline
        muted
        style={{ display: isCameraReady && !isLoading ? 'block' : 'none' }}
      />
      <canvas
        ref={canvasRef}
        className={styles.overlayCanvas}
        style={{ display: isCameraReady && !isLoading ? 'block' : 'none' }}
      />

      {!isCameraReady && !isLoading && !error && (
        <div className={styles.preparationMessage}>ì¹´ë©”ë¼ë¥¼ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”... ì ì‹œë§Œìš”!</div>
      )}

      {!isLoading && isCameraReady && (
        <button
          onClick={handleTakePhoto}
          className={styles.shutterButton}
          aria-label="ì‚¬ì§„ ì°ê¸°"
          disabled={isLoading}
        >
        </button>
      )}

      {showPopup && capturedImageForPopup && apiResultForPopup && (
        <ResultPopup
          capturedImage={capturedImageForPopup}
          resultText={apiResultForPopup.celebrityName}
          onClose={handleClosePopup}
        />
      )}
    </div>
  );
};

export default CameraView;